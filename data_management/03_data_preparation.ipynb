{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6fd39978-1737-49aa-b7dc-73112e1be1a3",
   "metadata": {},
   "source": [
    "# Health Policy Data Preparation and Feature Store Integration\n",
    "This notebook loads the integrated NHIS dataset with regional metrics and prepares it for feature engineering and storage in SageMaker Feature Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6bdd7067-0bba-495a-ad9c-e276f15e7170",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/pydantic/_internal/_fields.py:192: UserWarning: Field name \"json\" in \"MonitoringDatasetFormat\" shadows an attribute in parent \"Base\"\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/sagemaker-user/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import io\n",
    "import time\n",
    "from datetime import datetime\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a24ed9cd-5e2c-41a2-92f6-7b137ff210fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SageMaker Session: <sagemaker.session.Session object at 0x7f8aad4026d0>\n",
      "Bucket: usd-team1-ads508\n",
      "Region: us-east-1\n"
     ]
    }
   ],
   "source": [
    "# Initialize SageMaker session and AWS environment\n",
    "sess = sagemaker.Session()\n",
    "bucket = \"usd-team1-ads508\"  # Use your project bucket\n",
    "role = sagemaker.get_execution_role()\n",
    "region = boto3.Session().region_name\n",
    "sm = boto3.Session().client(service_name=\"sagemaker\", region_name=region)\n",
    "s3 = boto3.Session().client(service_name=\"s3\", region_name=region)\n",
    "s3_resource = boto3.resource('s3')\n",
    "print(f\"SageMaker Session: {sess}\")\n",
    "print(f\"Bucket: {bucket}\")\n",
    "print(f\"Region: {region}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19bb4ca0-ef2f-4bc7-a5a0-fba48d7ca946",
   "metadata": {},
   "source": [
    "# SECTION 1: Load the Dataset from S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43c1b0c0-dc3e-4507-adca-3f6b01a8c814",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_data_key = \"nhis_with_regional_metrics.csv\"\n",
    "s3_data_path = f\"s3://{bucket}/{s3_data_key}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95816553-afb3-4a34-8fb1-23bdfcab641f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (150220, 18)\n",
      "\n",
      "First few rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>evercovd_a</th>\n",
       "      <th>shtcvd191_a</th>\n",
       "      <th>empdysmss3_a</th>\n",
       "      <th>hicov_a</th>\n",
       "      <th>emdindstn1_a</th>\n",
       "      <th>sex_a</th>\n",
       "      <th>agep_a</th>\n",
       "      <th>educp_a</th>\n",
       "      <th>region</th>\n",
       "      <th>industry_avg_estimate</th>\n",
       "      <th>avg_uninsured_rate</th>\n",
       "      <th>avg_obesity_rate</th>\n",
       "      <th>avg_poor_fair_health</th>\n",
       "      <th>avg_flu_vaccination_rate</th>\n",
       "      <th>avg_adult_smoking</th>\n",
       "      <th>avg_physical_inactivity</th>\n",
       "      <th>avg_median_household_income</th>\n",
       "      <th>srvy_yr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>36</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.067532</td>\n",
       "      <td>0.315695</td>\n",
       "      <td>0.171813</td>\n",
       "      <td>0.495664</td>\n",
       "      <td>0.184924</td>\n",
       "      <td>0.269075</td>\n",
       "      <td>67477.836283</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>61</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.067532</td>\n",
       "      <td>0.315695</td>\n",
       "      <td>0.171813</td>\n",
       "      <td>0.495664</td>\n",
       "      <td>0.184924</td>\n",
       "      <td>0.269075</td>\n",
       "      <td>67477.836283</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>73</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.067532</td>\n",
       "      <td>0.315695</td>\n",
       "      <td>0.171813</td>\n",
       "      <td>0.495664</td>\n",
       "      <td>0.184924</td>\n",
       "      <td>0.269075</td>\n",
       "      <td>67477.836283</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>80</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.067532</td>\n",
       "      <td>0.315695</td>\n",
       "      <td>0.171813</td>\n",
       "      <td>0.495664</td>\n",
       "      <td>0.184924</td>\n",
       "      <td>0.269075</td>\n",
       "      <td>67477.836283</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.067532</td>\n",
       "      <td>0.315695</td>\n",
       "      <td>0.171813</td>\n",
       "      <td>0.495664</td>\n",
       "      <td>0.184924</td>\n",
       "      <td>0.269075</td>\n",
       "      <td>67477.836283</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   evercovd_a  shtcvd191_a  empdysmss3_a  hicov_a  emdindstn1_a  sex_a  \\\n",
       "0         1.0          1.0           2.0        1           NaN      2   \n",
       "1         1.0          1.0           2.0        1           NaN      2   \n",
       "2         1.0          1.0           NaN        1           NaN      2   \n",
       "3         2.0          1.0           NaN        1           NaN      2   \n",
       "4         1.0          1.0           2.0        1           NaN      2   \n",
       "\n",
       "   agep_a  educp_a  region  industry_avg_estimate  avg_uninsured_rate  \\\n",
       "0      36        8       1                    NaN            0.067532   \n",
       "1      61        7       1                    NaN            0.067532   \n",
       "2      73        8       1                    NaN            0.067532   \n",
       "3      80        9       1                    NaN            0.067532   \n",
       "4      27        9       1                    NaN            0.067532   \n",
       "\n",
       "   avg_obesity_rate  avg_poor_fair_health  avg_flu_vaccination_rate  \\\n",
       "0          0.315695              0.171813                  0.495664   \n",
       "1          0.315695              0.171813                  0.495664   \n",
       "2          0.315695              0.171813                  0.495664   \n",
       "3          0.315695              0.171813                  0.495664   \n",
       "4          0.315695              0.171813                  0.495664   \n",
       "\n",
       "   avg_adult_smoking  avg_physical_inactivity  avg_median_household_income  \\\n",
       "0           0.184924                 0.269075                 67477.836283   \n",
       "1           0.184924                 0.269075                 67477.836283   \n",
       "2           0.184924                 0.269075                 67477.836283   \n",
       "3           0.184924                 0.269075                 67477.836283   \n",
       "4           0.184924                 0.269075                 67477.836283   \n",
       "\n",
       "   srvy_yr  \n",
       "0     2022  \n",
       "1     2022  \n",
       "2     2022  \n",
       "3     2022  \n",
       "4     2022  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download the CSV file from S3\n",
    "obj = s3_resource.Object(bucket, s3_data_key)\n",
    "data = obj.get()['Body'].read()\n",
    "df = pd.read_csv(io.BytesIO(data))\n",
    "print(f\"Shape: {df.shape}\")\n",
    "print(\"\\nFirst few rows:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5bad1bea-2132-4cc1-9b1d-57b21c613ea7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Original column information:\n",
      "- evercovd_a: float64\n",
      "- shtcvd191_a: float64\n",
      "- empdysmss3_a: float64\n",
      "- hicov_a: int64\n",
      "- emdindstn1_a: float64\n",
      "- sex_a: int64\n",
      "- agep_a: int64\n",
      "- educp_a: int64\n",
      "- region: int64\n",
      "- industry_avg_estimate: float64\n",
      "- avg_uninsured_rate: float64\n",
      "- avg_obesity_rate: float64\n",
      "- avg_poor_fair_health: float64\n",
      "- avg_flu_vaccination_rate: float64\n",
      "- avg_adult_smoking: float64\n",
      "- avg_physical_inactivity: float64\n",
      "- avg_median_household_income: float64\n",
      "- srvy_yr: int64\n"
     ]
    }
   ],
   "source": [
    "# Display column information\n",
    "print(\"\\nOriginal column information:\")\n",
    "for col in df.columns:\n",
    "    print(f\"- {col}: {df[col].dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "218b2612-8ebb-4a54-ab82-21f0f509c00f",
   "metadata": {},
   "source": [
    "# SECTION 2: Data Quality Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1438baea-0f2b-47f2-8dc6-7df986f9bb65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing values per column:\n",
      "evercovd_a                      45853\n",
      "shtcvd191_a                     71089\n",
      "empdysmss3_a                    57656\n",
      "hicov_a                             0\n",
      "emdindstn1_a                    94783\n",
      "sex_a                               0\n",
      "agep_a                              0\n",
      "educp_a                             0\n",
      "region                              0\n",
      "industry_avg_estimate          101102\n",
      "avg_uninsured_rate                  0\n",
      "avg_obesity_rate                    0\n",
      "avg_poor_fair_health                0\n",
      "avg_flu_vaccination_rate            0\n",
      "avg_adult_smoking                   0\n",
      "avg_physical_inactivity             0\n",
      "avg_median_household_income         0\n",
      "srvy_yr                             0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "missing_values = df.isnull().sum()\n",
    "print(\"\\nMissing values per column:\")\n",
    "print(missing_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e834805-c4c3-4fcc-a7c7-6df7f826108c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Columns with >30% missing values: ['evercovd_a', 'shtcvd191_a', 'empdysmss3_a', 'emdindstn1_a', 'industry_avg_estimate']\n"
     ]
    }
   ],
   "source": [
    "# Calculate percentage of missing values\n",
    "missing_percentage = (missing_values / len(df)) * 100\n",
    "columns_to_check = missing_percentage[missing_percentage > 30].index.tolist()\n",
    "print(f\"\\nColumns with >30% missing values: {columns_to_check}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "13a8c31a-5189-4405-9205-7cba63cb27e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Basic statistics for key numeric columns:\n",
      "          evercovd_a   shtcvd191_a  empdysmss3_a       hicov_a  emdindstn1_a  \\\n",
      "count  104367.000000  79131.000000  92564.000000  150220.00000  55437.000000   \n",
      "mean        1.783466      1.332221     14.343730       1.07527     53.588380   \n",
      "std         0.700685      1.006633     99.821748       0.35957     21.392442   \n",
      "min         1.000000      1.000000      0.000000       1.00000      1.000000   \n",
      "25%         1.000000      1.000000      0.000000       1.00000     42.000000   \n",
      "50%         2.000000      1.000000      0.000000       1.00000     61.000000   \n",
      "75%         2.000000      1.000000      3.000000       1.00000     66.000000   \n",
      "max         9.000000      9.000000    999.000000       9.00000     99.000000   \n",
      "\n",
      "               sex_a         agep_a        educp_a         region  \\\n",
      "count  150220.000000  150220.000000  150220.000000  150220.000000   \n",
      "mean        1.543370      52.928585       6.427074       2.697058   \n",
      "std         0.502349      18.463964       7.048306       1.022535   \n",
      "min         1.000000      18.000000       0.000000       1.000000   \n",
      "25%         1.000000      37.000000       4.000000       2.000000   \n",
      "50%         2.000000      54.000000       6.000000       3.000000   \n",
      "75%         2.000000      68.000000       8.000000       4.000000   \n",
      "max         9.000000      99.000000      99.000000       4.000000   \n",
      "\n",
      "       industry_avg_estimate  avg_uninsured_rate  avg_obesity_rate  \\\n",
      "count           49118.000000       150220.000000     150220.000000   \n",
      "mean               56.929162            0.111112          0.329104   \n",
      "std                19.980060            0.027217          0.031409   \n",
      "min                25.285714            0.064514          0.271069   \n",
      "25%                37.928571            0.090653          0.305394   \n",
      "50%                63.000000            0.114338          0.331765   \n",
      "75%                69.656250            0.139767          0.348728   \n",
      "max                98.000000            0.144514          0.381865   \n",
      "\n",
      "       avg_poor_fair_health  avg_flu_vaccination_rate  avg_adult_smoking  \\\n",
      "count         150220.000000             150220.000000      150220.000000   \n",
      "mean               0.178574                  0.427548           0.186954   \n",
      "std                0.031632                  0.038506           0.022941   \n",
      "min                0.122712                  0.361398           0.150140   \n",
      "25%                0.155060                  0.400631           0.167557   \n",
      "50%                0.173079                  0.426606           0.187746   \n",
      "75%                0.202653                  0.441769           0.213009   \n",
      "max                0.238026                  0.528186           0.225750   \n",
      "\n",
      "       avg_physical_inactivity  avg_median_household_income        srvy_yr  \n",
      "count            150220.000000                150220.000000  150220.000000  \n",
      "mean                  0.260401                 56937.743488    2020.940973  \n",
      "std                   0.036323                  6078.484669       1.424377  \n",
      "min                   0.197885                 47056.143850    2019.000000  \n",
      "25%                   0.230119                 52928.276476    2020.000000  \n",
      "50%                   0.260803                 55582.634459    2021.000000  \n",
      "75%                   0.290361                 61028.876106    2022.000000  \n",
      "max                   0.335740                 70403.110619    2023.000000  \n"
     ]
    }
   ],
   "source": [
    "numeric_columns = df.select_dtypes(include=['int64', 'float64']).columns\n",
    "print(\"\\nBasic statistics for key numeric columns:\")\n",
    "print(df[numeric_columns].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a88a8184-c850-4482-9792-0c083c4fd856",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Checking for special values in key categorical columns:\n",
      "\n",
      "evercovd_a value counts:\n",
      "evercovd_a\n",
      "1.0    27289\n",
      "2.0    76307\n",
      "7.0      128\n",
      "8.0      451\n",
      "9.0      192\n",
      "Name: count, dtype: int64\n",
      "\n",
      "shtcvd191_a value counts:\n",
      "shtcvd191_a\n",
      "1.0    61998\n",
      "2.0    15554\n",
      "7.0      381\n",
      "8.0     1135\n",
      "9.0       63\n",
      "Name: count, dtype: int64\n",
      "\n",
      "hicov_a value counts:\n",
      "hicov_a\n",
      "1    140160\n",
      "2      9853\n",
      "7       101\n",
      "9       106\n",
      "Name: count, dtype: int64\n",
      "\n",
      "emdindstn1_a value counts:\n",
      "emdindstn1_a\n",
      "1.0      395\n",
      "2.0      229\n",
      "3.0       52\n",
      "4.0       19\n",
      "5.0       64\n",
      "        ... \n",
      "78.0    3111\n",
      "79.0      37\n",
      "97.0     774\n",
      "98.0     186\n",
      "99.0      50\n",
      "Name: count, Length: 82, dtype: int64\n",
      "\n",
      "sex_a value counts:\n",
      "sex_a\n",
      "1    68687\n",
      "2    81517\n",
      "7       10\n",
      "9        6\n",
      "Name: count, dtype: int64\n",
      "\n",
      "educp_a value counts:\n",
      "educp_a\n",
      "0       152\n",
      "1     10351\n",
      "2      2340\n",
      "3      3412\n",
      "4     34023\n",
      "5     23091\n",
      "6      5830\n",
      "7     13603\n",
      "8     34425\n",
      "9     16548\n",
      "10     4299\n",
      "11     1373\n",
      "97      246\n",
      "99      527\n",
      "Name: count, dtype: int64\n",
      "\n",
      "region value counts:\n",
      "region\n",
      "1    25024\n",
      "2    33108\n",
      "3    54440\n",
      "4    37648\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for special values that might represent missing data or refusals\n",
    "print(\"\\nChecking for special values in key categorical columns:\")\n",
    "categorical_cols = ['evercovd_a', 'shtcvd191_a', 'hicov_a', 'emdindstn1_a', 'sex_a', 'educp_a', 'region']\n",
    "for col in categorical_cols:\n",
    "    if col in df.columns:\n",
    "        print(f\"\\n{col} value counts:\")\n",
    "        print(df[col].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d8694e-e81b-4f6f-a481-ee6ae2c83e5e",
   "metadata": {},
   "source": [
    "# SECTION 3: Create an Employee ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b43fe72a-4909-4911-84db-20af8c39f89a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a unique ID by combining srvy_yr and other identifying fields\n",
    "df['record_id'] = df.apply(\n",
    "    lambda row: f\"{row['srvy_yr']}_{row['region']}_{row['sex_a']}_{row['agep_a']}_{np.random.randint(10000, 99999)}\", \n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4834d3a4-f930-4d49-a18e-e0c9bd564e22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 150169 unique record IDs out of 150220 records\n"
     ]
    }
   ],
   "source": [
    "# Verify uniqueness\n",
    "unique_ids = df['record_id'].nunique()\n",
    "print(f\"Created {unique_ids} unique record IDs out of {len(df)} records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "879e8835-f796-4c48-9adc-0c6d3c54bdb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After regeneration: 150220 unique record IDs out of 150220 records\n"
     ]
    }
   ],
   "source": [
    "# If duplicate IDs exist, regenerate them to ensure uniqueness\n",
    "if unique_ids < len(df):\n",
    "    # Add another random component\n",
    "    df['record_id'] = df.apply(\n",
    "        lambda row: f\"{row['srvy_yr']}_{row['region']}_{row['sex_a']}_{row['agep_a']}_{np.random.randint(10000, 99999)}_{np.random.randint(1000, 9999)}\", \n",
    "        axis=1\n",
    "    )\n",
    "    unique_ids = df['record_id'].nunique()\n",
    "    print(f\"After regeneration: {unique_ids} unique record IDs out of {len(df)} records\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3aa51de-4c20-4309-9c9b-d6dce0770468",
   "metadata": {},
   "source": [
    "# SECTION 4: Data Cleaning and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "37caed49-9431-458d-8683-82f85f4baca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to identify and handle special values in survey data\n",
    "def clean_survey_code(df, column, special_values=[7, 8, 9], replacement=0):\n",
    "    \"\"\"\n",
    "    Replace special values (usually representing 'refused', 'don't know', etc.) with a specified value\n",
    "    \"\"\"\n",
    "    if column in df.columns:\n",
    "        # Create a copy to avoid modifying the original\n",
    "        df[column] = df[column].copy()\n",
    "        \n",
    "        # Replace special values\n",
    "        for val in special_values:\n",
    "            df[column] = df[column].replace(val, replacement)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3e994fae-2bd2-4bae-8e01-4edea416db50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean special values in the survey data columns\n",
    "for col in ['evercovd_a', 'shtcvd191_a', 'hicov_a', 'emdindstn1_a', 'sex_a', 'educp_a']:\n",
    "    df = clean_survey_code(df, col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9ea6daae-5763-4cc5-b6a5-a97ff88b496c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle missing values for the target variable (days missed from work)\n",
    "# First, clean any special codes in empdysmss3_a\n",
    "df = clean_survey_code(df, 'empdysmss3_a', special_values=[999], replacement=np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "191ed29f-3260-4030-9fe0-5753eb4971f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For empdysmss3_a, use 0 for missing values (assuming 0 days if not reported)\n",
    "df['empdysmss3_a'] = df['empdysmss3_a'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9652c6d5-7dbc-485e-81dd-d0dfc5c64f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For categorical variables, fill with most common value\n",
    "categorical_cols = ['evercovd_a', 'shtcvd191_a', 'hicov_a', 'emdindstn1_a', 'sex_a', 'educp_a', 'region']\n",
    "for col in categorical_cols:\n",
    "    if col in df.columns:\n",
    "        mode_value = df[col].mode()[0]\n",
    "        df[col] = df[col].fillna(mode_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a27baeb4-f0e9-4971-8966-9ddccf427f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For continuous variables, fill with median\n",
    "continuous_cols = ['agep_a', 'avg_uninsured_rate', 'avg_obesity_rate', \n",
    "                  'avg_flu_vaccination_rate', 'avg_adult_smoking', \n",
    "                  'avg_physical_inactivity', 'avg_median_household_income']\n",
    "for col in continuous_cols:\n",
    "    if col in df.columns:\n",
    "        median_value = df[col].median()\n",
    "        df[col] = df[col].fillna(median_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "866363bb-365b-485e-aa6e-057bb04b4f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure data types are correct\n",
    "# Convert to int\n",
    "for col in ['empdysmss3_a', 'hicov_a', 'sex_a', 'agep_a', 'educp_a', 'region', 'srvy_yr']:\n",
    "    if col in df.columns:\n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "807ab9e4-f259-4f3c-972e-5b4a76eed9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle potential binary columns\n",
    "for col in ['evercovd_a', 'shtcvd191_a']:\n",
    "    if col in df.columns:\n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "21d99ccb-81de-4f33-88c3-61214cffae50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert continuous features to float\n",
    "for col in ['avg_uninsured_rate', 'avg_obesity_rate', 'avg_poor_fair_health',\n",
    "            'avg_flu_vaccination_rate', 'avg_adult_smoking', 'avg_physical_inactivity', \n",
    "            'avg_median_household_income']:\n",
    "    if col in df.columns:\n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0.0).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bb193551-b246-4be4-917a-8d25bf84be2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle industry_avg_estimate, which has many missing values\n",
    "if 'industry_avg_estimate' in df.columns:\n",
    "    df['industry_avg_estimate'] = pd.to_numeric(df['industry_avg_estimate'], errors='coerce').fillna(0.0).astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f68d240-fe79-4b96-be36-551ce0f82ca1",
   "metadata": {},
   "source": [
    "# SECTION 5: Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bf32a3f7-dbd9-48ff-ae94-44accb561441",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numeric Feature Scaling\n",
    "def scale_numeric_features(df, columns_to_scale):\n",
    "    scaler = StandardScaler()\n",
    "    df_scaled = df.copy()\n",
    "    \n",
    "    # Remove non-finite values before scaling\n",
    "    for col in columns_to_scale:\n",
    "        df_scaled[col] = pd.to_numeric(df_scaled[col], errors='coerce')\n",
    "        df_scaled[col] = df_scaled[col].fillna(df_scaled[col].median())\n",
    "    \n",
    "    # Create scaled versions (new columns)\n",
    "    scaled_data = scaler.fit_transform(df_scaled[columns_to_scale])\n",
    "    \n",
    "    # Add scaled columns with new names\n",
    "    for i, col in enumerate(columns_to_scale):\n",
    "        df_scaled[f\"{col}_scaled\"] = scaled_data[:, i]\n",
    "    \n",
    "    return df_scaled, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2107b5ca-0c97-400a-8faa-8584275fd2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select numeric columns to scale (exclude target variable)\n",
    "numeric_cols_to_scale = ['agep_a', 'avg_uninsured_rate', 'avg_obesity_rate', \n",
    "                          'avg_flu_vaccination_rate', 'avg_adult_smoking', \n",
    "                          'avg_physical_inactivity', 'avg_median_household_income']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f745cdd3-44ab-4d78-b655-b4da297d0a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply scaling\n",
    "df, feature_scaler = scale_numeric_features(df, numeric_cols_to_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3da034f8-0bcd-49bf-a4be-9b754d9486e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical Feature Encoding\n",
    "# Binary encoding of Yes/No variables\n",
    "binary_cols = ['evercovd_a', 'shtcvd191_a', 'hicov_a']\n",
    "for col in binary_cols:\n",
    "    if col in df.columns:\n",
    "        # Map various codes to binary (1=Yes, 0=No/Unknown)\n",
    "        df[f\"{col}_binary\"] = df[col].apply(lambda x: 1 if x == 2 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "36a32f1f-03fe-4d47-9500-fd07ff8c777d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encode region\n",
    "df = pd.get_dummies(df, columns=['region'], prefix='region')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8a0fee5b-55df-4199-aba2-39dadd024cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode education level (ordinal encoding)\n",
    "if 'educp_a' in df.columns:\n",
    "    # Group education levels\n",
    "    df['education_level'] = df['educp_a'].apply(\n",
    "        lambda x: 1 if x in [0, 1, 2, 3] else  # Less than HS\n",
    "                  2 if x == 4 else  # HS graduate\n",
    "                  3 if x in [5, 6, 7] else  # Some college\n",
    "                  4 if x == 8 else  # Bachelor's\n",
    "                  5 if x in [9, 10, 11] else 3  # Graduate degree, default to some college\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a59baa29-8977-44b1-abb1-0b2933530bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode industry categories into broader groups\n",
    "if 'emdindstn1_a' in df.columns:\n",
    "    # Create industry groups based on 2-digit codes\n",
    "    industry_mapping = {\n",
    "        'agriculture': list(range(1, 6)),\n",
    "        'mining': list(range(6, 9)),\n",
    "        'utilities': [9],\n",
    "        'construction': [10],\n",
    "        'manufacturing': list(range(11, 32)),\n",
    "        'wholesale': list(range(32, 35)),\n",
    "        'retail': list(range(35, 47)),\n",
    "        'transportation': list(range(47, 50)),\n",
    "        'information': list(range(50, 54)),\n",
    "        'finance': list(range(54, 58)),\n",
    "        'real_estate': list(range(58, 61)),\n",
    "        'services': list(range(61, 72)),\n",
    "        'accommodation_food': list(range(72, 74)),\n",
    "        'other_services': list(range(74, 78)),\n",
    "        'public_admin': [78],\n",
    "        'military': [79]\n",
    "    }\n",
    "    \n",
    "    # Create a function to map the industry code to a group\n",
    "    def map_industry(code):\n",
    "        if pd.isna(code):\n",
    "            return 'unknown'\n",
    "        code = int(code)\n",
    "        for group, codes in industry_mapping.items():\n",
    "            if code in codes:\n",
    "                return group\n",
    "        return 'other'\n",
    "    \n",
    "    # Apply the mapping\n",
    "    df['industry_group'] = df['emdindstn1_a'].apply(map_industry)\n",
    "    \n",
    "    # One-hot encode the industry group\n",
    "    df = pd.get_dummies(df, columns=['industry_group'], prefix='ind')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f85b3514-9366-4c3e-bff2-1cfaf208a7b6",
   "metadata": {},
   "source": [
    "Create Feature Interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b8a2dd24-e4a1-4772-b287-1b9a3e1b39b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Age and insurance interaction\n",
    "df['age_insurance_interaction'] = df['agep_a'] * df['hicov_a_binary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a0799e24-4e4b-43f3-82b4-de454a60a4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create health risk score (combining obesity, smoking, and physical inactivity)\n",
    "df['health_risk_score'] = (\n",
    "    df['avg_obesity_rate_scaled'] + \n",
    "    df['avg_adult_smoking_scaled'] + \n",
    "    df['avg_physical_inactivity_scaled']\n",
    ") / 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dae4360-dfac-42c6-b83c-69ca35efdeb5",
   "metadata": {},
   "source": [
    "# SECTION 6: Train-Test Split for Model Development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "59cd446a-bc1d-43c5-81c9-615377b08081",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a column for split_type\n",
    "df['split_type'] = 'train'  # Default all to train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8835ce3c-d90b-49d3-968b-ba336d6b4441",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create stratified split based on empdysmss3_a (binned)\n",
    "# Create bins for the target variable\n",
    "df['absenteeism_bin'] = pd.qcut(df['empdysmss3_a'], q=5, labels=False, duplicates='drop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d7b87af9-8104-436e-8d78-dd5a00327ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform stratified split\n",
    "train_indices, test_indices = train_test_split(\n",
    "    df.index, \n",
    "    test_size=0.2, \n",
    "    random_state=42,\n",
    "    stratify=df['absenteeism_bin']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "913245ef-f55e-4216-a347-469b1d2b830a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign split types\n",
    "df.loc[test_indices, 'split_type'] = 'test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "968fb7ae-14d4-401c-975a-d24fd93f731b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: 120176 records\n",
      "Testing set: 30044 records\n"
     ]
    }
   ],
   "source": [
    "# Verify the split\n",
    "print(f\"Training set: {len(train_indices)} records\")\n",
    "print(f\"Testing set: {len(test_indices)} records\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1004256-6031-4580-bdfb-369342a2d948",
   "metadata": {},
   "source": [
    "# SECTION 7: Feature Store Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "972457fc-0522-4682-ab49-b3f8d1ca4661",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.feature_store.feature_definition import (\n",
    "    FeatureDefinition,\n",
    "    FeatureTypeEnum,\n",
    ")\n",
    "from sagemaker.feature_store.feature_group import FeatureGroup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b44fc604-3b87-4a83-9fd4-7e007c72259e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create timestamp for event time feature\n",
    "current_timestamp = datetime.now().strftime(\"%Y-%m-%dT%H:%M:%SZ\")\n",
    "df['event_time'] = current_timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d80deaaa-e788-49d8-bb01-f96a2fc5b5d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Group name: health-policy-features-20250331-083045\n"
     ]
    }
   ],
   "source": [
    "# Define Feature Group name with timestamp to ensure uniqueness\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "feature_group_name = f\"health-policy-features-{timestamp}\"\n",
    "print(f\"Feature Group name: {feature_group_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ffa179fc-91d2-4cdb-87f9-b338039e0f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Feature Definitions - with appropriate types\n",
    "feature_definitions = [\n",
    "    # Record identifier\n",
    "    FeatureDefinition(feature_name=\"record_id\", feature_type=FeatureTypeEnum.STRING),\n",
    "    \n",
    "    # Event time\n",
    "    FeatureDefinition(feature_name=\"event_time\", feature_type=FeatureTypeEnum.STRING),\n",
    "    \n",
    "    # Target variable\n",
    "    FeatureDefinition(feature_name=\"empdysmss3_a\", feature_type=FeatureTypeEnum.INTEGRAL),\n",
    "    \n",
    "    # Original features - carefully typecasted\n",
    "    FeatureDefinition(feature_name=\"srvy_yr\", feature_type=FeatureTypeEnum.INTEGRAL),\n",
    "    FeatureDefinition(feature_name=\"evercovd_a_binary\", feature_type=FeatureTypeEnum.INTEGRAL),\n",
    "    FeatureDefinition(feature_name=\"shtcvd191_a_binary\", feature_type=FeatureTypeEnum.INTEGRAL),\n",
    "    FeatureDefinition(feature_name=\"hicov_a_binary\", feature_type=FeatureTypeEnum.INTEGRAL),\n",
    "    FeatureDefinition(feature_name=\"sex_a\", feature_type=FeatureTypeEnum.INTEGRAL),\n",
    "    FeatureDefinition(feature_name=\"agep_a\", feature_type=FeatureTypeEnum.INTEGRAL),\n",
    "    FeatureDefinition(feature_name=\"education_level\", feature_type=FeatureTypeEnum.INTEGRAL),\n",
    "    \n",
    "    # Regional metrics - all as FRACTIONAL\n",
    "    FeatureDefinition(feature_name=\"avg_uninsured_rate\", feature_type=FeatureTypeEnum.FRACTIONAL),\n",
    "    FeatureDefinition(feature_name=\"avg_obesity_rate\", feature_type=FeatureTypeEnum.FRACTIONAL),\n",
    "    FeatureDefinition(feature_name=\"avg_poor_fair_health\", feature_type=FeatureTypeEnum.FRACTIONAL),\n",
    "    FeatureDefinition(feature_name=\"avg_flu_vaccination_rate\", feature_type=FeatureTypeEnum.FRACTIONAL),\n",
    "    FeatureDefinition(feature_name=\"avg_adult_smoking\", feature_type=FeatureTypeEnum.FRACTIONAL),\n",
    "    FeatureDefinition(feature_name=\"avg_physical_inactivity\", feature_type=FeatureTypeEnum.FRACTIONAL),\n",
    "    FeatureDefinition(feature_name=\"avg_median_household_income\", feature_type=FeatureTypeEnum.FRACTIONAL),\n",
    "    \n",
    "    # Engineered features\n",
    "    FeatureDefinition(feature_name=\"health_risk_score\", feature_type=FeatureTypeEnum.FRACTIONAL),\n",
    "    FeatureDefinition(feature_name=\"age_insurance_interaction\", feature_type=FeatureTypeEnum.FRACTIONAL),\n",
    "    \n",
    "    # Region one-hot encoded columns\n",
    "    FeatureDefinition(feature_name=\"region_1\", feature_type=FeatureTypeEnum.INTEGRAL),\n",
    "    FeatureDefinition(feature_name=\"region_2\", feature_type=FeatureTypeEnum.INTEGRAL),\n",
    "    FeatureDefinition(feature_name=\"region_3\", feature_type=FeatureTypeEnum.INTEGRAL),\n",
    "    FeatureDefinition(feature_name=\"region_4\", feature_type=FeatureTypeEnum.INTEGRAL),\n",
    "    \n",
    "    # Split type for ML workflow\n",
    "    FeatureDefinition(feature_name=\"split_type\", feature_type=FeatureTypeEnum.STRING),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f74182b3-b279-4a64-a50b-b2582cc31613",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Feature Group\n",
    "feature_group = FeatureGroup(\n",
    "    name=feature_group_name, \n",
    "    feature_definitions=feature_definitions,\n",
    "    sagemaker_session=sess\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ce01947c-7862-4187-875a-25c357827360",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Offline store S3 prefix: health-policy-feature-store-20250331-083045\n"
     ]
    }
   ],
   "source": [
    "# Set S3 Prefix for Offline Feature Store\n",
    "offline_store_prefix = f\"health-policy-feature-store-{timestamp}\"\n",
    "print(f\"Offline store S3 prefix: {offline_store_prefix}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "709c2b29-1377-493a-9646-6a2e1c9ce115",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to prepare data for Feature Store\n",
    "def prepare_for_feature_store(df, feature_definitions):\n",
    "    \"\"\"\n",
    "    Prepare a DataFrame for ingestion into SageMaker Feature Store by ensuring\n",
    "    all columns match the expected types and all required columns are present.\n",
    "    \"\"\"\n",
    "    # Get feature names and types\n",
    "    feature_names = [feat.feature_name for feat in feature_definitions]\n",
    "    feature_types = {feat.feature_name: feat.feature_type for feat in feature_definitions}\n",
    "    \n",
    "    # Create a new DataFrame with only the columns needed for Feature Store\n",
    "    cols_to_include = [col for col in feature_names if col in df.columns]\n",
    "    df_features = df[cols_to_include].copy()\n",
    "    \n",
    "    # Make sure all required columns exist\n",
    "    for col in feature_names:\n",
    "        if col not in df_features.columns:\n",
    "            if feature_types[col] == FeatureTypeEnum.STRING:\n",
    "                df_features[col] = \"\"\n",
    "            elif feature_types[col] == FeatureTypeEnum.INTEGRAL:\n",
    "                df_features[col] = 0\n",
    "            elif feature_types[col] == FeatureTypeEnum.FRACTIONAL:\n",
    "                df_features[col] = 0.0\n",
    "    \n",
    "    # Ensure correct types for each column\n",
    "    for col, feat_type in feature_types.items():\n",
    "        if feat_type == FeatureTypeEnum.STRING:\n",
    "            df_features[col] = df_features[col].fillna(\"\").astype(str)\n",
    "        elif feat_type == FeatureTypeEnum.INTEGRAL:\n",
    "            df_features[col] = pd.to_numeric(df_features[col], errors='coerce').fillna(0).astype(int)\n",
    "        elif feat_type == FeatureTypeEnum.FRACTIONAL:\n",
    "            df_features[col] = pd.to_numeric(df_features[col], errors='coerce').fillna(0.0).astype(float)\n",
    "    \n",
    "    return df_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a96eb449-a500-4b9a-aca9-0531a275be38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for Feature Store\n",
    "df_features = prepare_for_feature_store(df, feature_definitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "511b8e8f-2eba-452c-8849-240bd1e1e453",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Verifying column types after preparation:\n",
      "- record_id: object (expected FeatureTypeEnum.STRING)\n",
      "- event_time: object (expected FeatureTypeEnum.STRING)\n",
      "- empdysmss3_a: int64 (expected FeatureTypeEnum.INTEGRAL)\n",
      "- srvy_yr: int64 (expected FeatureTypeEnum.INTEGRAL)\n",
      "- evercovd_a_binary: int64 (expected FeatureTypeEnum.INTEGRAL)\n",
      "- shtcvd191_a_binary: int64 (expected FeatureTypeEnum.INTEGRAL)\n",
      "- hicov_a_binary: int64 (expected FeatureTypeEnum.INTEGRAL)\n",
      "- sex_a: int64 (expected FeatureTypeEnum.INTEGRAL)\n",
      "- agep_a: int64 (expected FeatureTypeEnum.INTEGRAL)\n",
      "- education_level: int64 (expected FeatureTypeEnum.INTEGRAL)\n",
      "- avg_uninsured_rate: float64 (expected FeatureTypeEnum.FRACTIONAL)\n",
      "- avg_obesity_rate: float64 (expected FeatureTypeEnum.FRACTIONAL)\n",
      "- avg_poor_fair_health: float64 (expected FeatureTypeEnum.FRACTIONAL)\n",
      "- avg_flu_vaccination_rate: float64 (expected FeatureTypeEnum.FRACTIONAL)\n",
      "- avg_adult_smoking: float64 (expected FeatureTypeEnum.FRACTIONAL)\n",
      "- avg_physical_inactivity: float64 (expected FeatureTypeEnum.FRACTIONAL)\n",
      "- avg_median_household_income: float64 (expected FeatureTypeEnum.FRACTIONAL)\n",
      "- health_risk_score: float64 (expected FeatureTypeEnum.FRACTIONAL)\n",
      "- age_insurance_interaction: float64 (expected FeatureTypeEnum.FRACTIONAL)\n",
      "- region_1: int64 (expected FeatureTypeEnum.INTEGRAL)\n",
      "- region_2: int64 (expected FeatureTypeEnum.INTEGRAL)\n",
      "- region_3: int64 (expected FeatureTypeEnum.INTEGRAL)\n",
      "- region_4: int64 (expected FeatureTypeEnum.INTEGRAL)\n",
      "- split_type: object (expected FeatureTypeEnum.STRING)\n"
     ]
    }
   ],
   "source": [
    "# Verify data types match feature definitions\n",
    "print(\"\\nVerifying column types after preparation:\")\n",
    "for feat in feature_definitions:\n",
    "    col_name = feat.feature_name\n",
    "    if col_name in df_features.columns:\n",
    "        print(f\"- {col_name}: {df_features[col_name].dtype} (expected {feat.feature_type})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b868ffee-1c9e-4a26-87f0-668aa77202fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature group health-policy-features-20250331-083045 creation initiated.\n"
     ]
    }
   ],
   "source": [
    "# Create the Feature Group\n",
    "try:\n",
    "    feature_group.create(\n",
    "        s3_uri=f\"s3://{bucket}/{offline_store_prefix}\",\n",
    "        record_identifier_name=\"record_id\",\n",
    "        event_time_feature_name=\"event_time\",\n",
    "        role_arn=role,\n",
    "        enable_online_store=False\n",
    "    )\n",
    "    print(f\"Feature group {feature_group_name} creation initiated.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error creating feature group: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "aa1c28cb-a19a-448d-86bb-5a23a33f8770",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for feature group creation to complete.\n",
      "Initial status: Creating\n",
      "Waiting for Feature Group Creation.\n",
      "Waiting for Feature Group Creation.\n",
      "Waiting for Feature Group Creation.\n",
      "FeatureGroup health-policy-features-20250331-083045 successfully created.\n"
     ]
    }
   ],
   "source": [
    "# Wait for Feature Group Creation to Complete\n",
    "def wait_for_feature_group_creation_complete(feature_group):\n",
    "    status = feature_group.describe().get(\"FeatureGroupStatus\")\n",
    "    print(f\"Initial status: {status}\")\n",
    "    \n",
    "    while status == \"Creating\":\n",
    "        print(\"Waiting for Feature Group Creation.\")\n",
    "        time.sleep(10)\n",
    "        status = feature_group.describe().get(\"FeatureGroupStatus\")\n",
    "        \n",
    "    if status != \"Created\":\n",
    "        raise RuntimeError(f\"Failed to create feature group {feature_group.name}\")\n",
    "    print(f\"FeatureGroup {feature_group.name} successfully created.\")\n",
    "\n",
    "try:\n",
    "    print(\"Waiting for feature group creation to complete.\")\n",
    "    wait_for_feature_group_creation_complete(feature_group=feature_group)\n",
    "except Exception as e:\n",
    "    print(f\"Error waiting for feature group creation: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f9669e85-eb35-4421-b796-35a808a2c31f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ingesting 10000 records into feature store.\n",
      "Data ingestion complete!\n"
     ]
    }
   ],
   "source": [
    "# Ingest Data into Feature Store\n",
    "sample_size = min(10000, len(df_features))\n",
    "df_sample = df_features.sample(n=sample_size, random_state=42)\n",
    "\n",
    "try:\n",
    "    print(f\"\\nIngesting {len(df_sample)} records into feature store.\")\n",
    "    feature_group.ingest(data_frame=df_sample, max_workers=3, wait=True)\n",
    "    print(\"Data ingestion complete!\")\n",
    "except Exception as e:\n",
    "    print(f\"Error during ingestion: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb91ba09-eb84-41f9-878a-a7e742f46b5e",
   "metadata": {},
   "source": [
    "# SECTION 7: Data Validation and Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1ca42289-d679-4cbf-9236-61a2a18f552a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking for data in offline store\n",
      "Waiting for data in offline store\n",
      "Waiting for data in offline store\n",
      "Waiting for data in offline store\n",
      "Waiting for data in offline store\n",
      "Waiting for data in offline store\n"
     ]
    }
   ],
   "source": [
    "# Wait for data in offline store to become available\n",
    "try:\n",
    "    print(\"Checking for data in offline store\")\n",
    "    offline_store_contents = None\n",
    "    attempts = 0\n",
    "    while offline_store_contents is None and attempts < 5:\n",
    "        objects_in_bucket = s3.list_objects(Bucket=bucket, Prefix=offline_store_prefix)\n",
    "        if \"Contents\" in objects_in_bucket and len(objects_in_bucket[\"Contents\"]) > 1:\n",
    "            offline_store_contents = objects_in_bucket[\"Contents\"]\n",
    "            print(f\"Found {len(offline_store_contents)} objects in offline store.\")\n",
    "        else:\n",
    "            print(\"Waiting for data in offline store\")\n",
    "            attempts += 1\n",
    "            time.sleep(30)\n",
    "except Exception as e:\n",
    "    print(f\"Error checking offline store: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1409139-4339-4b15-aae1-c15f9593381c",
   "metadata": {},
   "source": [
    "# SECTION 8: Prepare Data for Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d6b8f8db-5cdd-4fcd-91ae-42338cb7c1a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved processed modeling data to s3://usd-team1-ads508/processed-health-data-20250331-083045.csv\n",
      "\n",
      "Summary of key variables for modeling:\n",
      "  Target variable (empdysmss3_a) mean: 4.12 days\n",
      "  Target variable (empdysmss3_a) median: 0.00 days\n",
      "  Target variable (empdysmss3_a) max: 998.00 days\n",
      "  Records with health insurance: 9853 (6.6%)\n",
      "  Average age: 52.9 years\n",
      "\n",
      "Data preparation complete! Your dataset is now ready for modeling.\n"
     ]
    }
   ],
   "source": [
    "# Save processed features to S3 for model training\n",
    "processed_data_key = f\"processed-health-data-{timestamp}.csv\"\n",
    "\n",
    "try:\n",
    "    # Select relevant columns for modeling\n",
    "    modeling_columns = [\n",
    "        # Target\n",
    "        'empdysmss3_a',\n",
    "        \n",
    "        # Demographics\n",
    "        'agep_a', 'sex_a', 'education_level',\n",
    "        \n",
    "        # Health indicators\n",
    "        'evercovd_a_binary', 'shtcvd191_a_binary', 'hicov_a_binary',\n",
    "        \n",
    "        # Regional metrics\n",
    "        'avg_uninsured_rate', 'avg_obesity_rate', 'avg_flu_vaccination_rate',\n",
    "        'avg_adult_smoking', 'avg_physical_inactivity', 'avg_median_household_income',\n",
    "        \n",
    "        # Industry information (one-hot encoded columns)\n",
    "        *[col for col in df.columns if col.startswith('ind_')],\n",
    "        \n",
    "        # Region indicators\n",
    "        *[col for col in df.columns if col.startswith('region_')],\n",
    "        \n",
    "        # Engineered features\n",
    "        'health_risk_score', 'age_insurance_interaction',\n",
    "        \n",
    "        # Split type\n",
    "        'split_type'\n",
    "    ]\n",
    "    \n",
    "    # Select only columns that exist in the dataframe\n",
    "    existing_modeling_columns = [col for col in modeling_columns if col in df.columns]\n",
    "    df_modeling = df[existing_modeling_columns]\n",
    "    \n",
    "    # Save to CSV and upload to S3\n",
    "    csv_buffer = io.StringIO()\n",
    "    df_modeling.to_csv(csv_buffer, index=False)\n",
    "    s3.put_object(\n",
    "        Bucket=bucket,\n",
    "        Key=processed_data_key,\n",
    "        Body=csv_buffer.getvalue()\n",
    "    )\n",
    "    print(f\"Saved processed modeling data to s3://{bucket}/{processed_data_key}\")\n",
    "    \n",
    "    # Print summary of key variables\n",
    "    print(\"\\nSummary of key variables for modeling:\")\n",
    "    print(f\"  Target variable (empdysmss3_a) mean: {df_modeling['empdysmss3_a'].mean():.2f} days\")\n",
    "    print(f\"  Target variable (empdysmss3_a) median: {df_modeling['empdysmss3_a'].median():.2f} days\")\n",
    "    print(f\"  Target variable (empdysmss3_a) max: {df_modeling['empdysmss3_a'].max():.2f} days\")\n",
    "    print(f\"  Records with health insurance: {df[df['hicov_a_binary'] == 1].shape[0]} ({df[df['hicov_a_binary'] == 1].shape[0]/df.shape[0]*100:.1f}%)\")\n",
    "    print(f\"  Average age: {df_modeling['agep_a'].mean():.1f} years\")\n",
    "    \n",
    "    print(\"\\nData preparation complete! Your dataset is now ready for modeling.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error in final data preparation: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a412edfd-d2b9-47c1-8ec0-ba7c291c4f6f",
   "metadata": {},
   "source": [
    "## Release Resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ebf3ce04-2ab1-47ca-9b81-e7b368d8f59e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<p><b>Shutting down your kernel for this notebook to release resources.</b></p>\n",
       "<button class=\"sm-command-button\" data-commandlinker-command=\"kernelmenu:shutdown\" style=\"display:none;\">Shutdown Kernel</button>\n",
       "        \n",
       "<script>\n",
       "try {\n",
       "    els = document.getElementsByClassName(\"sm-command-button\");\n",
       "    els[0].click();\n",
       "}\n",
       "catch(err) {\n",
       "    // NoOp\n",
       "}    \n",
       "</script>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "\n",
    "<p><b>Shutting down your kernel for this notebook to release resources.</b></p>\n",
    "<button class=\"sm-command-button\" data-commandlinker-command=\"kernelmenu:shutdown\" style=\"display:none;\">Shutdown Kernel</button>\n",
    "        \n",
    "<script>\n",
    "try {\n",
    "    els = document.getElementsByClassName(\"sm-command-button\");\n",
    "    els[0].click();\n",
    "}\n",
    "catch(err) {\n",
    "    // NoOp\n",
    "}    \n",
    "</script>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "35f466e2-94b4-4fff-8546-8fd6e84797c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "try {\n",
       "    Jupyter.notebook.save_checkpoint();\n",
       "    Jupyter.notebook.session.delete();\n",
       "}\n",
       "catch(err) {\n",
       "    // NoOp\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "\n",
    "try {\n",
    "    Jupyter.notebook.save_checkpoint();\n",
    "    Jupyter.notebook.session.delete();\n",
    "}\n",
    "catch(err) {\n",
    "    // NoOp\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
